---
layout:     post
title:      如何处理类别不平衡的数据集?
subtitle:   介绍几种经典且实用的不平衡数据集处理方法
date:       2020-09-09
author:     予以初始
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 深度学习
    - 机器学习
    - 数据挖掘
---

# 1 问题定义

**这是典型的数据类型不平衡问题**。比如对于一个二分类任务，训练集中类别为0的负样本占样本总数的90%，而正样本只占10%。那么这样的训练集有什么弊端呢？

如果类别不平衡的样本直接丢给模型学习，那么很显然模型会在负样本上的学习效果更好，因为模型‘看到’的负样本更多。举个栗子，就像你如果花9天时间去学习数学，花一天时间去学习语文，不出意外你会在数学考试中表现更好。

那么对于类别不平衡的训练集，该如何处理呢？

做过视频或者广告点击预估比赛的小伙伴应该经常遇到这种问题，这类比赛的训练集一般都是非常不平衡的，正样本的比例通常不足10%。这里我总结了一些在比赛中用过的一些行之有效的处理方法，下面为大家逐一介绍。

**Tips：是不是类别平衡的训练集就一定更好呢？这个不能保证，但对于大多数情况，类别平衡的数据对模型来说是更友好的，至少模型不会倾向于数量多的那一类别。**

# 2 解决方法 
## 2.1 采样

这是解决数据类别不平衡的**最简单、最暴力**的方法。

如果负样本太多，那就对负样本进行欠采样，就是随机的从负样本中抽取一部分样本，然后与正样本合并成训练集丢给模型训练。这样有个很明显的弊端，就是会造成严重的信息损失，数据收集不易，你还要丢弃一部分，很显然不合理。

如果正样本太少，那就对正样本进行过采样，就是对正样本进行复制，或者如果是NLP、CV任务，可以做一些数据增强，以此来增加正样本的数量。但是对于一般的任务来说，简单的对正样本进行复制，以此来达到增加正样本数量的目的，这样会使模型在这正样本上过拟合，因为模型‘看到’太多次这样的样本。就像你如果复习同一道题太多次，答案都背住了，所以看到类似的题就直接写答案，不会变通显然是不对的。

所以采样的方法不是解决类别不平衡问题的权宜之计，慎用。

## 2.2 SMOTE方法
上面介绍了对正样本进行过采样，会使模型过拟合的问题，SMOTE也是基于采样的方法，但是SMOTE可以降低过拟合的风险。

过采样是直接对样本进行复制，导致训练集重复样本太多，而SMOTE则不是直接复制，而是生成与正样本相似并且训练集中没有的样本。具体做法：**首先随机选取一个正样本，然后用K近邻选取一个与其最相似的样本，取两样本的中值或者均值，作为新样本**。这样生成的样本可一定程度降低模型过拟合的风险 (仍然可能过拟合) 。

**Tips：如果你对K近邻有些陌生，可以参考我的[这篇文章](https://zhuanlan.zhihu.com/p/160800727)做个简单的回顾。**

## 2.3 阈值调整

调整阈值也是比较简单而且有效的方法，这也是我在做比赛时经常会用到的方法。

对于二分类任务来说，一般会以0.5作为阈值来划分正负样本(比如逻辑回归)，预测概率值大于0.5则判定为正样本，反之为负样本。对于类别不平衡的训练集来说，这个阈值就不再合适了，因为当使用负样本来更新模型权重时，权重的更新会使模型的输出尽量偏向于0，如果负样本太多，那么负样本对于模型权重的更新量就比较多，使得模型输出接近0的概率就比较大，所以可以根据正负样本所占的比例来调整阈值。比如正样本只占10%，则可以将阈值调整为0.1，输出概率大于0.1的则判定为正样本，这样可以很好的解决类别不平衡问题，调整阈值是个简单且高效的方法。

也可以在计算每个样本的loss时，通过为正样本增加权重的方式，来优化样本不平衡问题。该方法原理跟划分阈值类似，正样本对权重的更新会使模型输出尽可能偏向于1，但是正样本太少，所以一方面可以降低划分为正样本的阈值，另一方面则可以在计算loss时，增加正样本权重，从而增大正样本对模型参数的更新量，提高模型输出为1的概率。

## 2.4 模型融合

模型融合不仅可以提升预测的准确性，其实也可以解决类别不平衡问题。

比如对于正样本(10%)、负样本(90%)的训练集，可以将负样本均等拆分为9份（注意一定要同分布拆分），然后每一份都与正样本组合成为一个小训练集，得到9份类别平衡的数据。然后用9个模型分别去训练(可以使用有差异性的模型, 使预测精度更高)，然后可以对9个模型的预测结果加权累加，作为最终的输出。最优的权重通常难以抉择，可以使用一个LR将9个模型的输出作为输入，通过训练让模型自己学习每个模型对应的权重即可。

通过模型融合就可以保证每个模型的训练数据都是类别平衡的数据，并且还能提升预测的准确性，一举两得。

**Tips：做一个小小的总结，方法一简单粗暴，方法二复杂、收益低，方法三和四是我最常用到的两种，简单且高效。当你遇到类别不平衡的数据时，可以参照以上几种方法进行尝试，至于哪种方法更有效还得通过实践来证明。**


**如果感到有收获，就请点个赞吧～万分感谢！**

**update on 09/09**
